{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MFCCExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Bgb_ytDNCzBwCDfGkLPRnW53Gu0ROnWy",
      "authorship_tag": "ABX9TyNZosYkQZNgHY0KNFBih28R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dalton-rutledge/Tweeter/blob/master/MFCCExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-2kjFeo4lZD",
        "colab_type": "code",
        "outputId": "f3eb98c1-e626-45e5-eb88-516cdb57f4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#install pudub before anything else for some sound processing functionality\n",
        "! pip install pydub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpkP-3pwBGe-",
        "colab_type": "code",
        "outputId": "a009ef95-6a40-46f9-98d5-ea1f3af71e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Dalton Rutledge\n",
        "Tweeter Model Development 2019-2020 Capstone\n",
        "\n",
        "This file contains methods and code that allows you to extract MFCCs from all audio files in a directory (in google drive) and save that data as a csv\n",
        "This file will also be coding out data into numeric classes 0 through 9\n",
        "\n",
        "CLASS to number code LIST:\n",
        "    0 - American Crow\n",
        "    1 - Black-capped Chickadee\n",
        "    2 - Cactus Wren\n",
        "    3 - House Finch\n",
        "    4 - Mourning Dove \n",
        "    5 - Northern Cardinal\n",
        "    6 - Wood Thrush (Call)\n",
        "    7 - Wood Thrush (Song)\n",
        "    8 - Tufted Titmouse\n",
        "    9 - White Breasted Nuthatch\n",
        "'''\n",
        "\n",
        "###IMPORTANT: MOUNT THE DRIVE BEFORE RUNNING!\n",
        "\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "data_directories = [\"/content/drive/My Drive/Tweeter/trainingData/AmericanCrow\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/BlackcappedChickadee\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/CactusWren\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/HouseFinch\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/MourningDove\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/NorthernCardinal\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/WoodThrushCall\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/WoodThrushSong\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/tuftedTitMouse\",\n",
        "                    \"/content/drive/My Drive/Tweeter/trainingData/whiteBreastedNuthatch\"\n",
        "                    ]\n",
        "\n",
        "\n",
        "#Uses librosa to extract mfccs from a single audio file. Returns mfccs. \n",
        "def extractFeatures(file_path):\n",
        "    audio, sample_rate = librosa.load(file_path)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=20)\n",
        "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
        "    return mfccs_processed\n",
        "\n",
        "#Calls extractFeatures on all .mp3 files (converted to .wav for librosa) in a list of directories, and saves this data as a csv\n",
        "def getData(list_of_directories):\n",
        "    features = []\n",
        "    class_label = 0\n",
        "    for directory in data_directories:\n",
        "        for filename in os.listdir(directory):\n",
        "            if filename.endswith(\".mp3\"):\n",
        "                file_path = os.path.join(os.path.abspath(directory), filename)\n",
        "                data = extractFeatures(file_path)\n",
        "                features.append([list(data), class_label])\n",
        "        class_label += 1\n",
        "    featuresDF = pandas.DataFrame(features)\n",
        "    featuresDF.to_csv('/content/drive/My Drive/Tweeter/trainingData/FinalTESTMFCC.csv')\n",
        "    return featuresDF\n",
        "\n",
        "#featuresdf = getData(data_directories)    UNCOMMENT THIS LINE OF CODE TO GENERATE A NEW FEATURES CSV\n",
        "print(\"i worked good :)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i worked good :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpV0Cpy_3bZe",
        "colab_type": "code",
        "outputId": "f25187b2-ba70-493f-b799-b8476c6e9f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#run this code block to see what returned mfccs look like, and how we average them\n",
        "audio, sample_rate = librosa.load(\"/content/drive/My Drive/Tweeter/trainingData/AmericanCrow/1.mp3\")\n",
        "mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=20)\n",
        "print(mfccs)                       \n",
        "print(len(mfccs[0]))\n",
        "print(np.mean(mfccs[0]))\n",
        "mfccs_processed = np.mean(mfccs.T,axis=0)\n",
        "print(mfccs_processed)\n",
        "print(len(mfccs_processed))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-546.17537466 -546.17537466 -402.77646135 ... -185.11302292\n",
            "  -256.14063676 -478.73061532]\n",
            " [   0.            0.           52.33208305 ...   40.4833786\n",
            "    42.39417025   36.97722662]\n",
            " [   0.            0.          -10.76096625 ...   -5.25841996\n",
            "     1.56990882    9.99687778]\n",
            " ...\n",
            " [   0.            0.           -3.70000658 ...   -7.9374226\n",
            "   -10.14073705   -8.60791055]\n",
            " [   0.            0.           -3.97941192 ...   -1.94960676\n",
            "    -6.20989014   -2.23488975]\n",
            " [   0.            0.           -4.06994471 ...    2.31235319\n",
            "     3.2934662     3.45470103]]\n",
            "236\n",
            "-107.78727091222292\n",
            "[-107.78727091   27.8873093   -52.25086789  -21.28091671  -18.66253111\n",
            "   19.92436765  -18.64387288  -14.76690476  -27.22685445    8.33763415\n",
            "  -13.91587007    3.39686486  -11.55909716    2.32430421  -18.52766984\n",
            "   -1.21917856   -7.1912224    -6.23804845   -1.98997334    0.55126912]\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNRiZS5vGmnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "import librosa\n",
        "from scipy.io import wavfile as wav\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow.keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztTtQagBHTJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresdf.rename(columns={0:'features',1:'label'},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3oEsSX9GqvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(featuresdf.features.tolist())\n",
        "y = np.array(featuresdf.label.tolist())\n",
        "# Encode the classification labels\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suP7UB7SGrnH",
        "colab_type": "code",
        "outputId": "ee0134e3-324b-4395-87b8-1a8d48f7ce7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# split the dataset \n",
        "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 128)\n",
        "print(x_train[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUrDmnmRGum4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = yy.shape[1]\n",
        "filter_size = 2\n",
        "model = None\n",
        "def build_model_graph(input_shape=(20,)):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_dim=20))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_labels))\n",
        "    model.add(Activation('softmax'))\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "    return model\n",
        "    \n",
        "model = build_model_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnuoV6mEGwt1",
        "colab_type": "code",
        "outputId": "ffc77ff6-ba8c-485b-e234-a4f4d7a04c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint \n",
        "from datetime import datetime \n",
        "num_epochs = 100\n",
        "num_batch_size = 32\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 296 samples, validate on 74 samples\n",
            "Epoch 1/100\n",
            "296/296 [==============================] - 0s 1ms/step - loss: 38.3778 - accuracy: 0.1081 - val_loss: 6.3243 - val_accuracy: 0.2703\n",
            "Epoch 2/100\n",
            "296/296 [==============================] - 0s 257us/step - loss: 20.8708 - accuracy: 0.2128 - val_loss: 3.7206 - val_accuracy: 0.4324\n",
            "Epoch 3/100\n",
            "296/296 [==============================] - 0s 223us/step - loss: 15.8558 - accuracy: 0.2399 - val_loss: 2.4803 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "296/296 [==============================] - 0s 210us/step - loss: 11.6093 - accuracy: 0.3514 - val_loss: 1.5998 - val_accuracy: 0.6622\n",
            "Epoch 5/100\n",
            "296/296 [==============================] - 0s 232us/step - loss: 9.2981 - accuracy: 0.3412 - val_loss: 1.8606 - val_accuracy: 0.5270\n",
            "Epoch 6/100\n",
            "296/296 [==============================] - 0s 211us/step - loss: 6.7558 - accuracy: 0.4088 - val_loss: 1.4477 - val_accuracy: 0.7027\n",
            "Epoch 7/100\n",
            "296/296 [==============================] - 0s 289us/step - loss: 5.4542 - accuracy: 0.4088 - val_loss: 1.0666 - val_accuracy: 0.5811\n",
            "Epoch 8/100\n",
            "296/296 [==============================] - 0s 215us/step - loss: 4.6357 - accuracy: 0.4595 - val_loss: 0.8602 - val_accuracy: 0.6486\n",
            "Epoch 9/100\n",
            "296/296 [==============================] - 0s 255us/step - loss: 4.1157 - accuracy: 0.4865 - val_loss: 1.0357 - val_accuracy: 0.6081\n",
            "Epoch 10/100\n",
            "296/296 [==============================] - 0s 240us/step - loss: 3.3072 - accuracy: 0.4966 - val_loss: 0.9722 - val_accuracy: 0.6216\n",
            "Epoch 11/100\n",
            "296/296 [==============================] - 0s 230us/step - loss: 3.1777 - accuracy: 0.4662 - val_loss: 1.1100 - val_accuracy: 0.6216\n",
            "Epoch 12/100\n",
            "296/296 [==============================] - 0s 229us/step - loss: 2.4947 - accuracy: 0.5101 - val_loss: 1.1377 - val_accuracy: 0.6216\n",
            "Epoch 13/100\n",
            "296/296 [==============================] - 0s 211us/step - loss: 2.6695 - accuracy: 0.4899 - val_loss: 1.1819 - val_accuracy: 0.6351\n",
            "Epoch 14/100\n",
            "296/296 [==============================] - 0s 255us/step - loss: 1.9553 - accuracy: 0.5574 - val_loss: 1.2453 - val_accuracy: 0.5946\n",
            "Epoch 15/100\n",
            "296/296 [==============================] - 0s 253us/step - loss: 1.7063 - accuracy: 0.5574 - val_loss: 1.2286 - val_accuracy: 0.6351\n",
            "Epoch 16/100\n",
            "296/296 [==============================] - 0s 229us/step - loss: 1.9152 - accuracy: 0.5169 - val_loss: 1.2195 - val_accuracy: 0.6757\n",
            "Epoch 17/100\n",
            "296/296 [==============================] - 0s 207us/step - loss: 1.5121 - accuracy: 0.6115 - val_loss: 1.2171 - val_accuracy: 0.6351\n",
            "Epoch 18/100\n",
            "296/296 [==============================] - 0s 246us/step - loss: 1.7334 - accuracy: 0.5405 - val_loss: 1.2304 - val_accuracy: 0.6486\n",
            "Epoch 19/100\n",
            "296/296 [==============================] - 0s 224us/step - loss: 1.4224 - accuracy: 0.6014 - val_loss: 1.1944 - val_accuracy: 0.6892\n",
            "Epoch 20/100\n",
            "296/296 [==============================] - 0s 240us/step - loss: 1.6569 - accuracy: 0.5709 - val_loss: 1.1248 - val_accuracy: 0.7703\n",
            "Epoch 21/100\n",
            "296/296 [==============================] - 0s 231us/step - loss: 1.4023 - accuracy: 0.6149 - val_loss: 1.1145 - val_accuracy: 0.7432\n",
            "Epoch 22/100\n",
            "296/296 [==============================] - 0s 227us/step - loss: 1.2122 - accuracy: 0.6284 - val_loss: 1.0344 - val_accuracy: 0.7297\n",
            "Epoch 23/100\n",
            "296/296 [==============================] - 0s 245us/step - loss: 1.2850 - accuracy: 0.6250 - val_loss: 0.9194 - val_accuracy: 0.7432\n",
            "Epoch 24/100\n",
            "296/296 [==============================] - 0s 224us/step - loss: 1.3179 - accuracy: 0.6047 - val_loss: 0.9059 - val_accuracy: 0.7568\n",
            "Epoch 25/100\n",
            "296/296 [==============================] - 0s 225us/step - loss: 1.2515 - accuracy: 0.6486 - val_loss: 0.8623 - val_accuracy: 0.7703\n",
            "Epoch 26/100\n",
            "296/296 [==============================] - 0s 256us/step - loss: 1.3006 - accuracy: 0.6216 - val_loss: 0.8942 - val_accuracy: 0.7568\n",
            "Epoch 27/100\n",
            "296/296 [==============================] - 0s 213us/step - loss: 1.0889 - accuracy: 0.6588 - val_loss: 0.8681 - val_accuracy: 0.7838\n",
            "Epoch 28/100\n",
            "296/296 [==============================] - 0s 211us/step - loss: 0.9074 - accuracy: 0.6892 - val_loss: 0.8011 - val_accuracy: 0.7703\n",
            "Epoch 29/100\n",
            "296/296 [==============================] - 0s 225us/step - loss: 0.9855 - accuracy: 0.6486 - val_loss: 0.7649 - val_accuracy: 0.8108\n",
            "Epoch 30/100\n",
            "296/296 [==============================] - 0s 220us/step - loss: 0.8653 - accuracy: 0.7196 - val_loss: 0.7152 - val_accuracy: 0.8649\n",
            "Epoch 31/100\n",
            "296/296 [==============================] - 0s 233us/step - loss: 1.0064 - accuracy: 0.6655 - val_loss: 0.7092 - val_accuracy: 0.8378\n",
            "Epoch 32/100\n",
            "296/296 [==============================] - 0s 223us/step - loss: 0.8498 - accuracy: 0.7297 - val_loss: 0.7118 - val_accuracy: 0.8108\n",
            "Epoch 33/100\n",
            "296/296 [==============================] - 0s 230us/step - loss: 0.8765 - accuracy: 0.7297 - val_loss: 0.7056 - val_accuracy: 0.7432\n",
            "Epoch 34/100\n",
            "296/296 [==============================] - 0s 222us/step - loss: 0.8833 - accuracy: 0.7027 - val_loss: 0.6984 - val_accuracy: 0.8243\n",
            "Epoch 35/100\n",
            "296/296 [==============================] - 0s 281us/step - loss: 0.7669 - accuracy: 0.7297 - val_loss: 0.6914 - val_accuracy: 0.7703\n",
            "Epoch 36/100\n",
            "296/296 [==============================] - 0s 240us/step - loss: 0.8241 - accuracy: 0.7331 - val_loss: 0.6444 - val_accuracy: 0.8108\n",
            "Epoch 37/100\n",
            "296/296 [==============================] - 0s 254us/step - loss: 0.7293 - accuracy: 0.7432 - val_loss: 0.6158 - val_accuracy: 0.7973\n",
            "Epoch 38/100\n",
            "296/296 [==============================] - 0s 223us/step - loss: 0.7767 - accuracy: 0.7432 - val_loss: 0.6112 - val_accuracy: 0.8243\n",
            "Epoch 39/100\n",
            "296/296 [==============================] - 0s 222us/step - loss: 0.7163 - accuracy: 0.7466 - val_loss: 0.6019 - val_accuracy: 0.8378\n",
            "Epoch 40/100\n",
            "296/296 [==============================] - 0s 221us/step - loss: 0.7394 - accuracy: 0.7601 - val_loss: 0.5898 - val_accuracy: 0.7838\n",
            "Epoch 41/100\n",
            "296/296 [==============================] - 0s 253us/step - loss: 0.7046 - accuracy: 0.7838 - val_loss: 0.5599 - val_accuracy: 0.8243\n",
            "Epoch 42/100\n",
            "296/296 [==============================] - 0s 208us/step - loss: 0.7389 - accuracy: 0.7601 - val_loss: 0.5559 - val_accuracy: 0.8108\n",
            "Epoch 43/100\n",
            "296/296 [==============================] - 0s 218us/step - loss: 0.5873 - accuracy: 0.8108 - val_loss: 0.5592 - val_accuracy: 0.7973\n",
            "Epoch 44/100\n",
            "296/296 [==============================] - 0s 218us/step - loss: 0.6918 - accuracy: 0.7770 - val_loss: 0.5306 - val_accuracy: 0.8243\n",
            "Epoch 45/100\n",
            "296/296 [==============================] - 0s 227us/step - loss: 0.7293 - accuracy: 0.7973 - val_loss: 0.5329 - val_accuracy: 0.8378\n",
            "Epoch 46/100\n",
            "296/296 [==============================] - 0s 233us/step - loss: 0.6832 - accuracy: 0.7736 - val_loss: 0.5404 - val_accuracy: 0.8108\n",
            "Epoch 47/100\n",
            "296/296 [==============================] - 0s 220us/step - loss: 0.6212 - accuracy: 0.7872 - val_loss: 0.5457 - val_accuracy: 0.8243\n",
            "Epoch 48/100\n",
            "296/296 [==============================] - 0s 254us/step - loss: 0.6729 - accuracy: 0.7703 - val_loss: 0.5094 - val_accuracy: 0.8514\n",
            "Epoch 49/100\n",
            "296/296 [==============================] - 0s 215us/step - loss: 0.5289 - accuracy: 0.8378 - val_loss: 0.4731 - val_accuracy: 0.8649\n",
            "Epoch 50/100\n",
            "296/296 [==============================] - 0s 247us/step - loss: 0.5069 - accuracy: 0.8277 - val_loss: 0.4546 - val_accuracy: 0.8378\n",
            "Epoch 51/100\n",
            "296/296 [==============================] - 0s 252us/step - loss: 0.5035 - accuracy: 0.8311 - val_loss: 0.4450 - val_accuracy: 0.8919\n",
            "Epoch 52/100\n",
            "296/296 [==============================] - 0s 248us/step - loss: 0.5734 - accuracy: 0.8108 - val_loss: 0.4232 - val_accuracy: 0.8649\n",
            "Epoch 53/100\n",
            "296/296 [==============================] - 0s 236us/step - loss: 0.5258 - accuracy: 0.8277 - val_loss: 0.4104 - val_accuracy: 0.8784\n",
            "Epoch 54/100\n",
            "296/296 [==============================] - 0s 228us/step - loss: 0.4280 - accuracy: 0.8345 - val_loss: 0.4383 - val_accuracy: 0.8514\n",
            "Epoch 55/100\n",
            "296/296 [==============================] - 0s 247us/step - loss: 0.4836 - accuracy: 0.8311 - val_loss: 0.4375 - val_accuracy: 0.8649\n",
            "Epoch 56/100\n",
            "296/296 [==============================] - 0s 246us/step - loss: 0.3981 - accuracy: 0.8581 - val_loss: 0.4336 - val_accuracy: 0.9054\n",
            "Epoch 57/100\n",
            "296/296 [==============================] - 0s 207us/step - loss: 0.3841 - accuracy: 0.8784 - val_loss: 0.4249 - val_accuracy: 0.8784\n",
            "Epoch 58/100\n",
            "296/296 [==============================] - 0s 240us/step - loss: 0.5315 - accuracy: 0.8277 - val_loss: 0.4046 - val_accuracy: 0.8784\n",
            "Epoch 59/100\n",
            "296/296 [==============================] - 0s 224us/step - loss: 0.5308 - accuracy: 0.8277 - val_loss: 0.3970 - val_accuracy: 0.8919\n",
            "Epoch 60/100\n",
            "296/296 [==============================] - 0s 252us/step - loss: 0.4071 - accuracy: 0.8581 - val_loss: 0.4055 - val_accuracy: 0.8784\n",
            "Epoch 61/100\n",
            "296/296 [==============================] - 0s 213us/step - loss: 0.4913 - accuracy: 0.8446 - val_loss: 0.4016 - val_accuracy: 0.8649\n",
            "Epoch 62/100\n",
            "296/296 [==============================] - 0s 210us/step - loss: 0.4602 - accuracy: 0.8345 - val_loss: 0.3870 - val_accuracy: 0.8243\n",
            "Epoch 63/100\n",
            "296/296 [==============================] - 0s 224us/step - loss: 0.4591 - accuracy: 0.8581 - val_loss: 0.3728 - val_accuracy: 0.8649\n",
            "Epoch 64/100\n",
            "296/296 [==============================] - 0s 292us/step - loss: 0.3999 - accuracy: 0.8851 - val_loss: 0.3614 - val_accuracy: 0.8784\n",
            "Epoch 65/100\n",
            "296/296 [==============================] - 0s 218us/step - loss: 0.3881 - accuracy: 0.8851 - val_loss: 0.3508 - val_accuracy: 0.9189\n",
            "Epoch 66/100\n",
            "296/296 [==============================] - 0s 222us/step - loss: 0.4039 - accuracy: 0.8345 - val_loss: 0.3510 - val_accuracy: 0.9189\n",
            "Epoch 67/100\n",
            "296/296 [==============================] - 0s 215us/step - loss: 0.3899 - accuracy: 0.8649 - val_loss: 0.3717 - val_accuracy: 0.8649\n",
            "Epoch 68/100\n",
            "296/296 [==============================] - 0s 217us/step - loss: 0.3759 - accuracy: 0.8784 - val_loss: 0.3639 - val_accuracy: 0.8919\n",
            "Epoch 69/100\n",
            "296/296 [==============================] - 0s 219us/step - loss: 0.3909 - accuracy: 0.8480 - val_loss: 0.3701 - val_accuracy: 0.8919\n",
            "Epoch 70/100\n",
            "296/296 [==============================] - 0s 233us/step - loss: 0.4230 - accuracy: 0.8547 - val_loss: 0.3747 - val_accuracy: 0.8919\n",
            "Epoch 71/100\n",
            "296/296 [==============================] - 0s 229us/step - loss: 0.2883 - accuracy: 0.8919 - val_loss: 0.3611 - val_accuracy: 0.8784\n",
            "Epoch 72/100\n",
            "296/296 [==============================] - 0s 219us/step - loss: 0.3854 - accuracy: 0.8818 - val_loss: 0.3341 - val_accuracy: 0.8919\n",
            "Epoch 73/100\n",
            "296/296 [==============================] - 0s 236us/step - loss: 0.3520 - accuracy: 0.8750 - val_loss: 0.3917 - val_accuracy: 0.8919\n",
            "Epoch 74/100\n",
            "296/296 [==============================] - 0s 219us/step - loss: 0.3603 - accuracy: 0.8986 - val_loss: 0.4345 - val_accuracy: 0.8514\n",
            "Epoch 75/100\n",
            "296/296 [==============================] - 0s 222us/step - loss: 0.3797 - accuracy: 0.8851 - val_loss: 0.3708 - val_accuracy: 0.8784\n",
            "Epoch 76/100\n",
            "296/296 [==============================] - 0s 246us/step - loss: 0.3298 - accuracy: 0.8851 - val_loss: 0.3341 - val_accuracy: 0.8784\n",
            "Epoch 77/100\n",
            "296/296 [==============================] - 0s 226us/step - loss: 0.3185 - accuracy: 0.8818 - val_loss: 0.3678 - val_accuracy: 0.8649\n",
            "Epoch 78/100\n",
            "296/296 [==============================] - 0s 225us/step - loss: 0.3254 - accuracy: 0.8919 - val_loss: 0.3633 - val_accuracy: 0.8378\n",
            "Epoch 79/100\n",
            "296/296 [==============================] - 0s 242us/step - loss: 0.3802 - accuracy: 0.8953 - val_loss: 0.3680 - val_accuracy: 0.9054\n",
            "Epoch 80/100\n",
            "296/296 [==============================] - 0s 218us/step - loss: 0.2305 - accuracy: 0.8986 - val_loss: 0.3654 - val_accuracy: 0.8919\n",
            "Epoch 81/100\n",
            "296/296 [==============================] - 0s 205us/step - loss: 0.3156 - accuracy: 0.9155 - val_loss: 0.3668 - val_accuracy: 0.8784\n",
            "Epoch 82/100\n",
            "296/296 [==============================] - 0s 225us/step - loss: 0.2679 - accuracy: 0.8885 - val_loss: 0.3638 - val_accuracy: 0.8649\n",
            "Epoch 83/100\n",
            "296/296 [==============================] - 0s 222us/step - loss: 0.2577 - accuracy: 0.9291 - val_loss: 0.3117 - val_accuracy: 0.9324\n",
            "Epoch 84/100\n",
            "296/296 [==============================] - 0s 240us/step - loss: 0.3012 - accuracy: 0.9054 - val_loss: 0.2997 - val_accuracy: 0.9189\n",
            "Epoch 85/100\n",
            "296/296 [==============================] - 0s 220us/step - loss: 0.2497 - accuracy: 0.9020 - val_loss: 0.3219 - val_accuracy: 0.8919\n",
            "Epoch 86/100\n",
            "296/296 [==============================] - 0s 233us/step - loss: 0.2488 - accuracy: 0.9054 - val_loss: 0.3118 - val_accuracy: 0.9189\n",
            "Epoch 87/100\n",
            "296/296 [==============================] - 0s 232us/step - loss: 0.2389 - accuracy: 0.9291 - val_loss: 0.3400 - val_accuracy: 0.8919\n",
            "Epoch 88/100\n",
            "296/296 [==============================] - 0s 220us/step - loss: 0.2288 - accuracy: 0.9291 - val_loss: 0.3801 - val_accuracy: 0.8919\n",
            "Epoch 89/100\n",
            "296/296 [==============================] - 0s 235us/step - loss: 0.2454 - accuracy: 0.9054 - val_loss: 0.3345 - val_accuracy: 0.9054\n",
            "Epoch 90/100\n",
            "296/296 [==============================] - 0s 232us/step - loss: 0.2264 - accuracy: 0.9088 - val_loss: 0.3030 - val_accuracy: 0.8919\n",
            "Epoch 91/100\n",
            "296/296 [==============================] - 0s 237us/step - loss: 0.2394 - accuracy: 0.9291 - val_loss: 0.3068 - val_accuracy: 0.8919\n",
            "Epoch 92/100\n",
            "296/296 [==============================] - 0s 221us/step - loss: 0.2837 - accuracy: 0.8953 - val_loss: 0.3347 - val_accuracy: 0.9054\n",
            "Epoch 93/100\n",
            "296/296 [==============================] - 0s 298us/step - loss: 0.2695 - accuracy: 0.9291 - val_loss: 0.3342 - val_accuracy: 0.9189\n",
            "Epoch 94/100\n",
            "296/296 [==============================] - 0s 245us/step - loss: 0.2295 - accuracy: 0.9155 - val_loss: 0.2852 - val_accuracy: 0.9054\n",
            "Epoch 95/100\n",
            "296/296 [==============================] - 0s 215us/step - loss: 0.2851 - accuracy: 0.9054 - val_loss: 0.2768 - val_accuracy: 0.9054\n",
            "Epoch 96/100\n",
            "296/296 [==============================] - 0s 217us/step - loss: 0.1730 - accuracy: 0.9257 - val_loss: 0.3011 - val_accuracy: 0.9054\n",
            "Epoch 97/100\n",
            "296/296 [==============================] - 0s 234us/step - loss: 0.2273 - accuracy: 0.8986 - val_loss: 0.3078 - val_accuracy: 0.9054\n",
            "Epoch 98/100\n",
            "296/296 [==============================] - 0s 251us/step - loss: 0.2574 - accuracy: 0.8953 - val_loss: 0.2742 - val_accuracy: 0.8919\n",
            "Epoch 99/100\n",
            "296/296 [==============================] - 0s 270us/step - loss: 0.1754 - accuracy: 0.9459 - val_loss: 0.2627 - val_accuracy: 0.9595\n",
            "Epoch 100/100\n",
            "296/296 [==============================] - 0s 257us/step - loss: 0.1678 - accuracy: 0.9324 - val_loss: 0.2603 - val_accuracy: 0.9189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0fdcd1ef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJOijXLYG1On",
        "colab_type": "code",
        "outputId": "17dfdcdf-3548-452a-bd9c-6765321c7add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 98.99%\n",
            "Testing Accuracy: 91.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvkxquz_O4JE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "ANN_file = \"/content/drive/My Drive/Tweeter/FinalKerasTEST.h5\"\n",
        "keras.models.save_model(model, ANN_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeZZl4PaN8c0",
        "colab_type": "code",
        "outputId": "db9e319e-86a0-4fca-876f-eeb6940c4364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               10752     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 278,538\n",
            "Trainable params: 278,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}